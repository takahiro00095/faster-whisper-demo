import streamlit as st
from faster_whisper import WhisperModel
import os
from pydub import AudioSegment  # è¿½åŠ : éŸ³å£°å‡¦ç†ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

# ä¸€æ™‚ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
UPLOAD_DIR = "/tmp"
os.makedirs(UPLOAD_DIR, exist_ok=True)

def preprocess_audio(file_path):
    """
    éŸ³å£°ã‚’Whisperå‘ã‘ã«æœ€é©åŒ–ã™ã‚‹é–¢æ•°
    1. ã‚¹ãƒ†ãƒ¬ã‚ª -> ãƒ¢ãƒãƒ©ãƒ«å¤‰æ›
    2. ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã‚’16kHzã«å¤‰æ›
    3. éŸ³é‡ã‚’æ­£è¦åŒ– (Normalize)
    """
    try:
        # éŸ³å£°èª­ã¿è¾¼ã¿
        audio = AudioSegment.from_file(file_path)
        
        # 1. ãƒ¢ãƒãƒ©ãƒ«åŒ– (Whisperã¯ãƒ¢ãƒãƒ©ãƒ«ã§å‡¦ç†ã™ã‚‹ãŸã‚)
        audio = audio.set_channels(1)
        
        # 2. 16kHzã«å¤‰æ› (Whisperã®ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ¬ãƒ¼ãƒˆ)
        audio = audio.set_frame_rate(16000)
        
        # 3. éŸ³é‡æ­£è¦åŒ– (-20dBFSã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«ã™ã‚‹)
        target_dBFS = -20.0
        change_in_dBFS = target_dBFS - audio.dBFS
        normalized_audio = audio.apply_gain(change_in_dBFS)
        
        # å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä½œæˆ (ä¾‹: audio.mp3 -> audio_prep.wav)
        base, _ = os.path.splitext(file_path)
        new_path = base + "_prep.wav"
        
        # æ›¸ãå‡ºã—
        normalized_audio.export(new_path, format="wav")
        return new_path, None
    except Exception as e:
        return None, f"å‰å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}"

st.title("ğŸª¶ FasterWhisper Demo")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
with st.sidebar:
    st.header("ãƒ¢ãƒ‡ãƒ«è¨­å®š")
    model_size = st.selectbox(
        "ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º", 
        ["large-v3-turbo", "medium", "small", "base"], 
        index=0
    )
    compute_type = st.selectbox("è¨ˆç®—ã‚¿ã‚¤ãƒ—", ["int8", "float16"], index=1)
    
    st.divider()
    
    st.header("ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    use_preprocessing = st.checkbox("éŸ³å£°ã®å‰å‡¦ç†ã‚’è¡Œã†", value=True, help="éŸ³é‡ã‚’å‡ä¸€åŒ–ã—ã€èªè­˜ç²¾åº¦ã‚’é«˜ã‚ã¾ã™ã€‚æ™‚é–“ãŒå°‘ã—ã‹ã‹ã‚Šã¾ã™ã€‚")
    use_vad = st.checkbox("VADãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ (ç„¡éŸ³é™¤å»)", value=True)
    beam_size = st.slider("Beam Size", 1, 5, 5, help="1ãŒæœ€é€Ÿã€‚5ãŒé«˜ç²¾åº¦ã€‚")

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
uploaded_file = st.file_uploader("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ« (mp3, wav, m4a)", type=["mp3", "wav", "m4a"])

if st.button("æ–‡å­—èµ·ã“ã—é–‹å§‹"):
    if uploaded_file is None:
        st.error("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚»ãƒƒãƒˆã—ã¦ãã ã•ã„")
    else:
        # 1. ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        file_path = os.path.join(UPLOAD_DIR, uploaded_file.name)
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        # 2. å‰å‡¦ç† (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
        final_file_path = file_path
        if use_preprocessing:
            with st.spinner("éŸ³å£°ã®å‰å‡¦ç†ä¸­ï¼ˆæ­£è¦åŒ–ãƒ»å¤‰æ›ï¼‰..."):
                prep_path, error = preprocess_audio(file_path)
                if error:
                    st.warning(f"å‰å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ: {error}")
                else:
                    final_file_path = prep_path
                    st.success("å‰å‡¦ç†å®Œäº†: éŸ³é‡ã‚’æœ€é©åŒ–ã—ã¾ã—ãŸ")

        # 3. ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
        try:
            st.info(f"ãƒ¢ãƒ‡ãƒ« '{model_size}' ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
            model = WhisperModel(model_size, device="cpu", compute_type=compute_type)
        except Exception as e:
            st.error(f"ãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ©ãƒ¼: {e}")
            st.stop()

        st.info("è§£æä¸­... (ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º)")
        
        # 4. æ¨è«–å®Ÿè¡Œ
        # VADã‚„BeamSizeãªã©ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
        segments, info = model.transcribe(
            final_file_path, 
            beam_size=beam_size, 
            vad_filter=use_vad,
            vad_parameters=dict(min_silence_duration_ms=500) if use_vad else None
        )
        
        st.success(f"æ¤œå‡ºè¨€èª: {info.language} (ç¢ºç‡: {int(info.language_probability * 100)}%)")

        # 5. çµæœè¡¨ç¤º (é«˜é€ŸåŒ–ãƒãƒ¼ã‚¸ãƒ§ãƒ³)
        full_text_list = []
        log_container = st.container()
        
        # ãƒ­ã‚°ã‚³ãƒ³ãƒ†ãƒŠã®é«˜ã•ã‚’æŒ‡å®šï¼ˆCSSãƒãƒƒã‚¯ãªã—ã®ç°¡æ˜“ç‰ˆï¼‰
        with log_container:
             for segment in segments:
                # start = f"{segment.start:.1f}"
                # end = f"{segment.end:.1f}"
                line = f"{segment.text}"
                
                # è»½ã„è¡¨ç¤ºãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨
                st.text(line) 
                full_text_list.append(line)

        # æœ€çµ‚çµæœå‡ºåŠ›
        output_text = "\n".join(full_text_list)
        st.divider()
        st.subheader("å…¨çµæœ (ã‚³ãƒ”ãƒ¼ç”¨)")
        st.text_area("çµæœ", output_text, height=400)